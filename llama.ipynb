{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c2a59a-05ca-46ec-8529-60fb7c8cb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from ollama import Client\n",
    "\n",
    "SERVER = 'http://localhost:11434'\n",
    "URI = '/v1/'\n",
    "\n",
    "MAX_OUTPUT_TOKENS = 50\n",
    "\n",
    "#TOTAL_RUNS = [1, 2, 3]\n",
    "#MODELS = ['mistral', 'llama3.1:8b', 'llama3.1:70b']\n",
    "#COLLEGES = ['College of Education', 'College of Science', 'College of Engineering and Computer Science']\n",
    "\n",
    "TOTAL_RUNS = [10000]\n",
    "MODELS =  ['mistral', 'llama3.1:8b', 'llama3.1:70b']\n",
    "COLLEGES = ['College of Education', 'College of Engineering and Computer Science', 'College of Science', ]\n",
    "\n",
    "PROMPT_FILE = 'prompt_simple.txt'\n",
    "\n",
    "# Set the CSV file and Read the CSV\n",
    "subject_headings_after_cleanup = \"../DATA/subject_headings_after_cleanup_without_blanks.csv\"\n",
    "df = pd.read_csv(subject_headings_after_cleanup) \n",
    "\n",
    "# additional information for the LLM\n",
    "ADDITIONAL_INSTRUCTION = \", ONLY PRINT THE HEADINGS AND NOTHING ELSE. OUTPUT THE HEADINGS AS A COMMA SEPARATATED VALUE.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2727ba5-0ee1-49c9-bde0-acc3dfcb5708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------\n",
    "# Methods areas\n",
    "def gen_prompt(PROMPT_FILE, college_df, COLLEGE):\n",
    "    with open(PROMPT_FILE, 'r') as file: \n",
    "        prompt = file.read()   \n",
    "    unique_headings_list = sorted(college_df['Subject Headings'].unique())\n",
    "    just_headings =  \", \".join(f\"'{item}'\" for item in unique_headings_list)    \n",
    "    prompt = prompt + \" \" + \"[\" + just_headings + \"]\" \n",
    "    return prompt\n",
    "\n",
    "\n",
    "# diplay dataframe info\n",
    "def get_data_info(selected_columns):    \n",
    "    print (\"--------------------------------------------\")\n",
    "    print(\"Number of rows:\", selected_columns.shape[0])\n",
    "    print(\"Number of columns:\", selected_columns.shape[1])\n",
    "    #selected_columns.info()\n",
    "\n",
    "\n",
    "def instantiate_client():\n",
    "    client = OpenAI(\n",
    "        base_url= SERVER + URI,\n",
    "        api_key='ollama', \n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "def llama_get_response_oai(client, MODEL, prompt, query):\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt },\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature = 1, \n",
    "        max_tokens = 100, \n",
    "        top_p = 1,\n",
    "        model = MODEL,\n",
    "    )  \n",
    "    response = chat_completion.choices[0].message\n",
    "    return response\n",
    "\n",
    "\n",
    "def llama_generate_prompt( title, abstract, additional_intructions = \"\"):\n",
    "    title = str(title)\n",
    "    abstract = str(abstract)    \n",
    "    query = \"Please find the subject headings for this example: \\n\" + title + \"\\n\" +  abstract + \"\\n\" + additional_intructions\n",
    "    return query\n",
    "\n",
    "\n",
    "def llama_gen_single(chosen_index):  \n",
    "    count = 1    \n",
    "    title = college_df['Title'][chosen_index]\n",
    "    abstract = college_df['Abstract'][chosen_index]\n",
    "    subject_heading = college_df['Subject Headings'][chosen_index]   \n",
    "    query = llama_generate_prompt( title, abstract, ADDITIONAL_INSTRUCTION)    \n",
    "    \n",
    "    response = llama_get_response_oai(client, prompt, query)    \n",
    "    \n",
    "    predicted_headings = response.content\n",
    "    foundHeading = predicted_headings.find(subject_heading)!= -1\n",
    "    predicted_headings = response.content        \n",
    "    llama_generate_report(title, subject_heading, predicted_headings, count , foundHeading )\n",
    "\n",
    "\n",
    "def llama_generate_report(title, subject_heading, predicted_headings, count, foundHeading ):\n",
    "    print(\"\\nTitle: \", title)\n",
    "    print(\"ACTUAL Subject Headings: \", subject_heading) \n",
    "    print(\"PREDICTED Subject Headings: \",  predicted_headings.split('\\n'))\n",
    "    print (\"Counted so far: \", count)\n",
    "    print (\"Heading Found so far: \", foundHeading)       \n",
    "    print (\"% Found Rate = \", (foundHeading * 100)/count)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "\n",
    "def llama_just_stat(MODEL, count, foundHeading):\n",
    "    print (\"Summary for MODEL: \", MODEL)\n",
    "    print (\"Counted : \", count)\n",
    "    print (\"Heading Found : \", foundHeading)       \n",
    "    print (\"% Found Rate = \", (foundHeading * 100)/count)\n",
    " \n",
    "# ---------------------------------------------------------------------------------------------\n",
    "# Run for all data\n",
    "\n",
    "def llama_gen_all(client, MODEL, prompt, NUMBER_OF_ITERATION ):\n",
    "    \n",
    "    count = 0\n",
    "    foundHeading = 0\n",
    "    \n",
    "    for index, row in college_df.iterrows():\n",
    "        count = count + 1\n",
    "        if count > NUMBER_OF_ITERATION:\n",
    "            break\n",
    "            \n",
    "        title = row['Title']\n",
    "        abstract = row['Abstract']\n",
    "        subject_heading =str(row['Subject Headings'])\n",
    "        \n",
    "        query = llama_generate_prompt( title, abstract, ADDITIONAL_INSTRUCTION)    \n",
    "        \n",
    "        response = llama_get_response_oai(client, MODEL, prompt, query)      \n",
    "    \n",
    "        # convert the response to lower case\n",
    "        predicted_headings = response.content.lower()  \n",
    "    \n",
    "        # convert the response into a list\n",
    "        # predicted_headings_list = predicted_headings\n",
    "    \n",
    "        # Tally the found headings\n",
    "        if (predicted_headings.find(subject_heading) != -1):\n",
    "                foundHeading = foundHeading + 1\n",
    "          \n",
    "        #print report\n",
    "        #llama_generate_report(title, subject_heading, predicted_headings, count, foundHeading )    \n",
    "\n",
    "    llama_just_stat(MODEL, count-1, foundHeading)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------\n",
    "#  Main Program\n",
    "\n",
    "# process a single abstract by providing the index\n",
    "# llama_gen_single(1)\n",
    "\n",
    "client = instantiate_client()\n",
    "\n",
    "for COLLEGE in COLLEGES:\n",
    "    \n",
    "    # Get College data\n",
    "    college_df = df[df['College'] == COLLEGE].reset_index(drop=True)\n",
    "    \n",
    "    # Data info\n",
    "    print (\"\\nCOLLEGE: \", COLLEGE)\n",
    "    get_data_info(college_df)   \n",
    "\n",
    "    # generate the prompt on the fly\n",
    "    prompt = gen_prompt(PROMPT_FILE, college_df, COLLEGE)\n",
    "  \n",
    "    for MODEL in MODELS:\n",
    "        for NUMBER_OF_ITERATION in TOTAL_RUNS:         \n",
    "            print(f\"\\nModel: {MODEL}, Number of iteration: {NUMBER_OF_ITERATION}\")\n",
    "            llama_gen_all(client, MODEL, prompt, NUMBER_OF_ITERATION)            \n",
    "        print (\"\\n\") \n",
    "            \n",
    "print (\"\\n******** DONE ********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4507e-2363-48a6-aa98-6bb993842487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
